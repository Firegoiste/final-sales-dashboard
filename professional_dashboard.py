# professional_dashboard.py (æœ€ç»ˆå®Œæ•´ç‰ˆ - ä¿®å¤æ‰€æœ‰å·²çŸ¥é”™è¯¯)

import streamlit as st
import pandas as pd
import sqlite3
from datetime import datetime, timedelta
from prophet import Prophet
import altair as alt
import math
from io import BytesIO
import matplotlib.pyplot as plt

# --- æ•°æ®åº“æ–‡ä»¶å ---
DATABASE_FILE = 'sales_database.db'

# --- é¡µé¢é…ç½® ---
st.set_page_config(layout="wide", page_title="ä¸“ä¸šé”€å”®æ•°æ®ä»ªè¡¨ç›˜")


# --- æ•°æ®åŠ è½½å‡½æ•° ---
@st.cache_data(ttl=600)
def load_data_from_db():
    try:
        conn = sqlite3.connect(DATABASE_FILE)
        df = pd.read_sql_query("SELECT * FROM sales", conn)
        conn.close()
        df['æ—¥æœŸ (Date)'] = pd.to_datetime(df['æ—¥æœŸ (Date)'])
        return df
    except Exception:
        return pd.DataFrame()


df_all = load_data_from_db()


# --- è¾…åŠ©å‡½æ•°ï¼šå¯¼å‡ºExcel ---
@st.cache_data
def to_excel(df):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()


# --- è‡ªç„¶è¯­è¨€ç†è§£ (NLU) æ ¸å¿ƒ ---
def parse_query(query, data_df):
    query_lower = query.lower().strip()
    if query_lower == 'ä½ å¥½' or query_lower == 'hello': return "ä½ å¥½å‘€ï¼æˆ‘æ˜¯æ‚¨çš„ä¸“å±é”€å”®æ•°æ®åˆ†æåŠ©æ‰‹~ ( Â´ â–½ ` )ï¾‰"
    if 'ä¸æ˜¯å“¥ä»¬' in query_lower: return "å“å‘€ï¼Œåˆ«åœ¨æ„è¿™äº›ç»†èŠ‚å˜›ï¼æˆ‘ä»¬è¿˜æ˜¯èŠèŠé”€å”®æ•°æ®å§~ O(âˆ©_âˆ©)O"
    all_reps = [str(rep).lower() for rep in data_df['é”€å”®ä»£è¡¨ (Rep)'].unique()]
    all_regions = [str(region).lower() for region in data_df['é”€å”®åŒºåŸŸ (Region)'].unique()]
    all_categories = [str(cat).lower() for cat in data_df['äº§å“å¤§ç±» (Category)'].unique()]
    found_entities = []
    found_rep = [rep for rep in all_reps if rep in query_lower]
    if found_rep: found_entities.extend(found_rep)
    found_region = [region for region in all_regions if region in query_lower]
    if found_region: found_entities.extend(found_region)
    found_category = [cat for cat in all_categories if cat in query_lower]
    if found_category: found_entities.extend(found_category)
    if not found_entities: return f"æŠ±æ­‰ï¼Œæ‚¨çš„é—®é¢˜ä¸­ä¸åŒ…å«å¯è¯†åˆ«çš„å…³é”®è¯ï¼ˆå¦‚é”€å”®ä»£è¡¨ã€åŒºåŸŸã€äº§å“å¤§ç±»ç­‰ï¼‰ï¼Œè¯·æ¢ä¸ªé—®æ³•è¯•è¯•å§ (T_T)"
    if found_rep and not found_region and not found_category:
        rep_name_original = [rep for rep in data_df['é”€å”®ä»£è¡¨ (Rep)'].unique() if rep.lower() in found_rep][0]
        rep_df = data_df[data_df['é”€å”®ä»£è¡¨ (Rep)'] == rep_name_original]
        if rep_df.empty: return f"æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°é”€å”®ä»£è¡¨ **{rep_name_original}** çš„è®°å½•ã€‚ (T_T)"
        total_sales = rep_df['é”€å”®é¢ (Sales)'].sum()
        region_sales = rep_df.groupby('é”€å”®åŒºåŸŸ (Region)')['é”€å”®é¢ (Sales)'].sum().sort_values(ascending=False)
        region_text = "\n#### **å¤§åŒºä¸šç»©åˆ†å¸ƒ:**\n"
        for region, sales in region_sales.items(): region_text += f"- **{region}:** Â¥ {sales:,.2f}\n"
        top_products = rep_df.groupby('äº§å“åç§° (Product)')['é”€å”®é¢ (Sales)'].sum().nlargest(3)
        product_text = "\n#### **Top 3 ç•…é”€äº§å“:**\n"
        for i, (product, sales) in enumerate(top_products.items(),
                                             1): product_text += f"**{i}. {product}:** Â¥ {sales:,.2f}\n"
        top_region = region_sales.index[0]
        top_category = rep_df.groupby('äº§å“å¤§ç±» (Category)')['é”€å”®é¢ (Sales)'].sum().idxmax()
        analysis_text = (f"\n#### **ç®€è¦åˆ†æ:**\n"
                         f"**{rep_name_original}** çš„ä¸šç»©ä¸»è¦é›†ä¸­åœ¨ **{top_region}** åŒºåŸŸã€‚"
                         f"ä»äº§å“æ¥çœ‹ï¼Œä»–/å¥¹æœ€æ“…é•¿é”€å”® **{top_category}** ç±»çš„äº§å“ã€‚")
        return (f"ä¸ºæ‚¨ç”Ÿæˆé”€å”®ä»£è¡¨ **{rep_name_original}** çš„ä¸šç»©æŠ¥å‘Šï¼š\n"
                f"### **æ€»é”€å”®é¢: Â¥ {total_sales:,.2f}**\n"
                f"{region_text}{product_text}{analysis_text}")
    filtered_df = data_df.copy()
    if found_rep:
        original_reps = [rep for rep in data_df['é”€å”®ä»£è¡¨ (Rep)'].unique() if str(rep).lower() in found_rep]
        filtered_df = filtered_df[filtered_df['é”€å”®ä»£è¡¨ (Rep)'].isin(original_reps)]
    if found_region:
        original_regions = [region for region in data_df['é”€å”®åŒºåŸŸ (Region)'].unique() if
                            str(region).lower() in found_region]
        filtered_df = filtered_df[filtered_df['é”€å”®åŒºåŸŸ (Region)'].isin(original_regions)]
    if found_category:
        original_categories = [cat for cat in data_df['äº§å“å¤§ç±» (Category)'].unique() if str(cat).lower() in found_category]
        filtered_df = filtered_df[filtered_df['äº§å“å¤§ç±» (Category)'].isin(original_categories)]
    if filtered_df.empty: return f"è™½ç„¶æ‚¨çš„é—®é¢˜æˆ‘å¬æ‡‚äº†ï¼Œä½†åœ¨æ•°æ®åº“é‡Œæš‚æœªæŸ¥è¯¢åˆ°å®Œå…¨åŒ¹é…çš„è®°å½•å“¦ (T_T)"
    if 'è®¢å•' in query_lower or 'å–äº†å¤šå°‘ç¬”' in query_lower:
        count = len(filtered_df)
        return f"æŸ¥è¯¢åˆ° **{count}** ç¬”ç›¸å…³è®¢å•ã€‚"
    else:
        total_sales = filtered_df['é”€å”®é¢ (Sales)'].sum()
        return f"æŸ¥è¯¢åˆ°çš„ç›¸å…³æ€»é”€å”®é¢ä¸º: **Â¥ {total_sales:,.2f}**"


# --- ä»ªè¡¨ç›˜ä¸»ç•Œé¢ ---
st.title("ğŸš€ ä¸“ä¸šé”€å”®æ•°æ®æ™ºèƒ½ä»ªè¡¨ç›˜")

if df_all.empty:
    st.warning("æ•°æ®åº“ä¸­å°šæ— æ•°æ®ã€‚è¯·å…ˆè¿è¡Œ `update_database.py` æ¥æ·»åŠ æ•°æ®ã€‚")
    st.stop()

# --- æ™ºèƒ½é—®ç­”åŒºåŸŸ ---
st.markdown("---")
st.header("ğŸ’¡ æ™ºèƒ½é—®ç­”å¼•æ“")
st.write("æ‚¨å¯ä»¥åƒèŠå¤©ä¸€æ ·æé—®ï¼Œä¾‹å¦‚ï¼šâ€œå¼ ä¸‰åœ¨åä¸œçš„æ€»ä¸šç»©æ˜¯å¤šå°‘ï¼Ÿâ€ æˆ– â€œè½¯ä»¶äº§å“æœ‰å¤šå°‘ç¬”è®¢å•ï¼Ÿâ€")
with st.form(key='qna_form'):
    user_query = st.text_input("è¯·åœ¨è¿™é‡Œè¾“å…¥æ‚¨çš„é—®é¢˜:", key='query_input')
    submit_button = st.form_submit_button(label='æäº¤é—®é¢˜')
if submit_button and user_query:
    with st.spinner("æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜å¹¶æŸ¥è¯¢æ•°æ®..."):
        answer = parse_query(user_query, df_all)
    st.info(f"**é—®:** {user_query}\n\n**ç­”:**\n{answer}")
st.markdown("---")

# --- ä¾§è¾¹æ ç­›é€‰å™¨ ---
st.sidebar.header("ç­›é€‰ä¸å¯¼èˆª")
selected_date = st.sidebar.date_input("é€‰æ‹©æŸ¥çœ‹æ—¥æœŸ", value=df_all['æ—¥æœŸ (Date)'].max(), min_value=df_all['æ—¥æœŸ (Date)'].min(),
                                      max_value=df_all['æ—¥æœŸ (Date)'].max())
all_reps_list = df_all['é”€å”®ä»£è¡¨ (Rep)'].unique()
all_categories_list = df_all['äº§å“å¤§ç±» (Category)'].unique()
selected_reps = st.sidebar.multiselect("é€‰æ‹©é”€å”®ä»£è¡¨", options=all_reps_list, default=all_reps_list)
selected_categories = st.sidebar.multiselect("é€‰æ‹©äº§å“å¤§ç±»", options=all_categories_list, default=all_categories_list)

# --- æ•°æ®ç­›é€‰é€»è¾‘ ---
selected_date = pd.to_datetime(selected_date)
df_selected_day_unfiltered = df_all[df_all['æ—¥æœŸ (Date)'].dt.date == selected_date.date()]
df_selected = df_selected_day_unfiltered[
    (df_selected_day_unfiltered['é”€å”®ä»£è¡¨ (Rep)'].isin(selected_reps)) &
    (df_selected_day_unfiltered['äº§å“å¤§ç±» (Category)'].isin(selected_categories))
    ]
df_previous = df_all[df_all['æ—¥æœŸ (Date)'].dt.date == (selected_date - timedelta(days=1)).date()]
df_last_week = df_all[df_all['æ—¥æœŸ (Date)'].dt.date == (selected_date - timedelta(days=7)).date()]

# --- ä¸»ç•Œé¢ ---
st.header(f"{selected_date.strftime('%Y-%m-%d')} å¸¸è§„ä»ªè¡¨ç›˜")

if df_selected.empty:
    st.warning(f"åœ¨å½“å‰ç­›é€‰æ¡ä»¶ä¸‹ï¼Œ {selected_date.strftime('%Y-%m-%d')} æ²¡æœ‰æ‰¾åˆ°é”€å”®æ•°æ®ã€‚")
else:
    # --- KPI å’ŒåŒæ¯”ç¯æ¯”åˆ†æ ---
    total_sales_selected = df_selected['é”€å”®é¢ (Sales)'].sum()
    total_sales_previous = df_previous['é”€å”®é¢ (Sales)'].sum()
    daily_growth_rate = ((
                                     total_sales_selected - total_sales_previous) / total_sales_previous) * 100 if total_sales_previous > 0 else 0
    total_sales_last_week = df_last_week['é”€å”®é¢ (Sales)'].sum()
    weekly_growth_rate = ((
                                      total_sales_selected - total_sales_last_week) / total_sales_last_week) * 100 if total_sales_last_week > 0 else 0

    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric(label="æ€»é”€å”®é¢ (ç­›é€‰å)", value=f"Â¥ {total_sales_selected:,.2f}", delta=f"{daily_growth_rate:.2f}% vs æ˜¨æ—¥å…¨é‡")
        st.caption(f"ä¸ä¸Šå‘¨åŒæœŸå…¨é‡å¯¹æ¯”: **{weekly_growth_rate:+.2f}%**")

    col2.metric("è®¢å•æ•° (ç­›é€‰å)", f"{len(df_selected)} å•")
    col3.metric("å¹³å‡å®¢å•ä»· (ç­›é€‰å)", f"Â¥ {df_selected['é”€å”®é¢ (Sales)'].mean():,.2f}")

    st.markdown("---")

    st.subheader("æœ¬æ—¥ Top 10 æ˜æ˜Ÿåˆ†æ (ç­›é€‰å)")
    col_rep, col_prod = st.columns(2)
    with col_rep:
        st.markdown("##### ğŸ† **Top 10 é”€å”®ä»£è¡¨**")
        top_reps = df_selected.groupby('é”€å”®ä»£è¡¨ (Rep)')['é”€å”®é¢ (Sales)'].sum().nlargest(10)
        st.dataframe(top_reps)
    with col_prod:
        st.markdown("##### ğŸš€ **Top 10 ç•…é”€äº§å“**")
        top_products = df_selected.groupby('äº§å“åç§° (Product)')['é”€å”®é¢ (Sales)'].sum().nlargest(10)
        st.dataframe(top_products)

    st.markdown("---")

    st.subheader("ä¸šç»©è´¡çŒ®åº¦åˆ†æ (å¸•ç´¯æ‰˜åˆ†æ)")
    all_reps_sales = df_selected.groupby('é”€å”®ä»£è¡¨ (Rep)')['é”€å”®é¢ (Sales)'].sum().sort_values(ascending=False)
    if len(all_reps_sales) > 0:
        num_top_20_percent = math.ceil(len(all_reps_sales) * 0.2)
        top_20_percent_reps = all_reps_sales.head(num_top_20_percent)
        top_reps_names = ', '.join(top_20_percent_reps.index.tolist())
        sales_from_top_20 = top_20_percent_reps.sum()
        contribution_percentage = (sales_from_top_20 / total_sales_selected) * 100
        st.info(f"ä¸šç»©æ’åå‰ **20%** çš„æ˜æ˜Ÿé”€å”® (**{top_reps_names}**)ï¼Œæ€»å…±è´¡çŒ®äº† **{contribution_percentage:.2f}%** çš„é”€å”®é¢ã€‚")
    else:
        st.info("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— é”€å”®æ•°æ®ï¼Œæ— æ³•è¿›è¡Œè´¡çŒ®åº¦åˆ†æã€‚")

    st.markdown("---")

    st.subheader("ğŸ“¥ æ•°æ®å¯¼å‡º")
    df_to_export = df_selected
    excel_data = to_excel(df_to_export)
    st.download_button(label="ğŸ“„ ä¸‹è½½å½“æ—¥ç­›é€‰åæ˜ç»†æ•°æ®", data=excel_data,
                       file_name=f"sales_details_{selected_date.strftime('%Y%m%d')}.xlsx")

    st.markdown("---")

    tab1, tab2, tab3 = st.tabs(["ğŸ“Š **å›¾è¡¨è”åŠ¨åˆ†æ (ç­›é€‰å)**", "ğŸ“ˆ å†å²è¶‹åŠ¿ (å…¨é‡)", "ğŸ”® é”€å”®é¢„æµ‹ (å…¨é‡)"])

    with tab1:
        st.subheader("å„ç»´åº¦é”€å”®é¢è¯¦æƒ… (ç‚¹å‡»å›¾è¡¨è¿›è¡Œè”åŠ¨ç­›é€‰)")

        # --- æ ¸å¿ƒä¿®æ”¹ï¼šç¡®ä¿æ‰€æœ‰åˆ—åéƒ½ä½¿ç”¨æ•°æ®è¡¨ä¸­çš„å®Œæ•´åç§° ---

        selection = alt.selection_multi(fields=['é”€å”®åŒºåŸŸ (Region)'], empty='all')  # ä½¿ç”¨æ­£ç¡®åˆ—å

        chart_region = alt.Chart(df_selected).mark_bar().encode(
            x=alt.X('é”€å”®åŒºåŸŸ (Region):N', title='é”€å”®åŒºåŸŸ'),  # ä½¿ç”¨æ­£ç¡®åˆ—å
            y=alt.Y('sum(é”€å”®é¢ (Sales)):Q', title='æ€»é”€å”®é¢ (å…ƒ)'),
            color=alt.condition(selection, alt.value('orange'), alt.value('steelblue')),
            tooltip=[alt.Tooltip('é”€å”®åŒºåŸŸ (Region):N', title='å¤§åŒº'), alt.Tooltip('sum(é”€å”®é¢ (Sales)):Q', format=',.2f')]
            # ä½¿ç”¨æ­£ç¡®åˆ—å
        ).add_selection(selection).properties(title='å„å¤§åŒºé”€å”®é¢')

        chart_category = alt.Chart(df_selected).mark_bar().encode(
            x=alt.X('äº§å“å¤§ç±» (Category):N', title='äº§å“å¤§ç±»'),
            y=alt.Y('sum(é”€å”®é¢ (Sales)):Q', title='æ€»é”€å”®é¢ (å…ƒ)'),
            tooltip=[alt.Tooltip('äº§å“å¤§ç±» (Category):N'), alt.Tooltip('sum(é”€å”®é¢ (Sales)):Q', format=',.2f')]
        ).transform_filter(selection).properties(title='å„äº§å“å¤§ç±»é”€å”®é¢ (å¯è¢«åŒºåŸŸç­›é€‰)')

        st.altair_chart(chart_region | chart_category, use_container_width=False)

    with tab2:
        st.subheader("å†å²é”€å”®æ€»é¢è¶‹åŠ¿ (å¯äº¤äº’)")
        daily_sales_history = df_all.groupby(df_all['æ—¥æœŸ (Date)'].dt.date)['é”€å”®é¢ (Sales)'].sum().reset_index()
        daily_sales_history.rename(columns={'æ—¥æœŸ (Date)': 'æ—¥æœŸ', 'é”€å”®é¢ (Sales)': 'é”€å”®é¢'}, inplace=True)
        chart = alt.Chart(daily_sales_history).mark_line(point=True, strokeWidth=2).encode(
            x=alt.X('æ—¥æœŸ:T', title='æ—¥æœŸ'),
            y=alt.Y('é”€å”®é¢:Q', title='æ€»é”€å”®é¢ (å…ƒ)'),
            tooltip=[alt.Tooltip('æ—¥æœŸ:T', format='%Y-%m-%d'), alt.Tooltip('é”€å”®é¢:Q', format=',.2f')]
        ).interactive()
        st.altair_chart(chart, use_container_width=True)

    with tab3:
        st.subheader("æœªæ¥é”€å”®é¢é¢„æµ‹ (Prophet æ¨¡å‹)")
        history_df = df_all[df_all['æ—¥æœŸ (Date)'].dt.date <= selected_date.date()].copy()
        daily_history = history_df.groupby(history_df['æ—¥æœŸ (Date)'].dt.date)['é”€å”®é¢ (Sales)'].sum().reset_index()
        prophet_df = daily_history.rename(columns={'æ—¥æœŸ (Date)': 'ds', 'é”€å”®é¢ (Sales)': 'y'})
        if len(prophet_df) < 14:
            st.warning("å†å²æ•°æ®ä¸è¶³14å¤©ï¼ŒProphet é¢„æµ‹å¯èƒ½ä¸å‡†ç¡®ã€‚")
        else:
            plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']
            plt.rcParams['axes.unicode_minus'] = False
            model = Prophet(interval_width=0.95)
            model.fit(prophet_df)
            future = model.make_future_dataframe(periods=30)
            forecast = model.predict(future)
            st.write("æ¨¡å‹åŸºäºè‡³ä»Šä¸ºæ­¢çš„æ‰€æœ‰å†å²æ•°æ®ï¼Œé¢„æµ‹æœªæ¥30å¤©çš„é”€å”®è¶‹åŠ¿ï¼š")
            fig = model.plot(forecast)
            ax = fig.gca()
            ax.set_xlabel("æ—¥æœŸ", fontsize=12)
            ax.set_ylabel("é¢„æµ‹é”€å”®é¢ (å…ƒ)", fontsize=12)
            ax.set_title("æœªæ¥30å¤©é”€å”®é¢é¢„æµ‹è¶‹åŠ¿", fontsize=16)
            st.pyplot(fig)
            st.write("è¯¦ç»†é¢„æµ‹æ•°æ®ï¼š")
            future_data = forecast.tail(30)
            display_forecast = future_data[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]
            display_forecast.rename(
                columns={'ds': 'æ—¥æœŸ', 'yhat': 'é¢„æµ‹å€¼', 'yhat_lower': 'é¢„æµ‹ä¸‹é™ (95%ç½®ä¿¡)', 'yhat_upper': 'é¢„æµ‹ä¸Šé™ (95%ç½®ä¿¡)'},
                inplace=True)
            display_forecast['æ—¥æœŸ'] = display_forecast['æ—¥æœŸ'].dt.strftime('%Y-%m-%d')
            st.dataframe(display_forecast)